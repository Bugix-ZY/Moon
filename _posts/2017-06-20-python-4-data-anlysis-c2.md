---
layout: post
title: Python for Data Analysis - C02 (1)
description: Python for Data Analysis ç¬¬äºŒç«  
category: blog
---

**Reference** :

*Python for Data Analysis*

---

[TOC]

### 1.usa.gov from bit.ly

æ‰¾åˆ°ä¸¤ä¸ªç½‘ç«™

https://www.data.gov/ 

https://www.usa.gov/developer 

ä¹¦ä¸Šçš„èµ„æºåœ¨è¿™é‡Œå¯ä»¥æ‰¾åˆ° -> http://1usagov.measuredvoice.com/

è·Ÿç€ä¹¦ä¸Šæ“ä½œä¸€ä¸‹çœ‹çœ‹ğŸ‘€

ç”¨çš„æ•°æ®æ˜¯`usagov_bitly_data2012-12-25-1356397867`, æ•°æ®çš„æ ¼å¼ä¸º `json`

#### è¯»å–æ•°æ®

* **æœ€ç®€å•çš„ python è¯»æ³• ä»¥åŠ ç”¨ `json` æ¨¡å—æ¥è¯»**

  `open(path).readline`å°±æ˜¯æœ€ç®€å•çš„ä¸€ç§æ–¹æ³•ï¼Œ`json.load()`ç”¨äº†` json` æ¨¡å—

  åŒæ—¶æ‰“å°å‡ºä»–ä»¬çš„ type çœ‹ï¼Œå‘ç°å‰è€…è¿”å› strï¼Œåè€…æ˜¯ä¸€ä¸ªè£… dict çš„ list

```python
def test():
    path = 'usagov_bitly_data2012-12-25-1356397867'
    # list comprehension - a concise way of applying an operation
    # to a collection of strings or other objects
    records = [json.loads(line) for line in open(path)]
    return  open(path).readline(), records

line, records = test()

print type(line), line
print type(records), type(records[0]), records[0]
print 'a: ', records[0]['a']
```

```json
<type 'str'> { "a": "Mozilla\/5.0 (iPod; CPU iPhone OS 511 like Mac OS X) AppleWebKit\/534.46 (KHTML, like Gecko) Mobile\/9B206", "c": "US", "nk": 1, "tz": "America\/Indianapolis", "gr": "IN", "g": "Vg7jBV", "h": "Vg7hKn", "l": "iembot", "al": "en-us", "hh": "1.usa.gov", "r": "http:\/\/t.co\/zcHxjnGZ", "u": "http:\/\/www.spc.noaa.gov\/products\/outlook\/archive\/2012\/day1otlk201212250100.html", "t": 1356397870, "hc": 1356397201, "cy": "Washington", "ll": [ 38.665798, -87.175903 ] }

<type 'list'> <type 'dict'> {u'a': u'Mozilla/5.0 (iPod; CPU iPhone OS 511 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Mobile/9B206', u'c': u'US', u'nk': 1, u'tz': u'America/Indianapolis', u'gr': u'IN', u'g': u'Vg7jBV', u'h': u'Vg7hKn', u'cy': u'Washington', u'l': u'iembot', u'al': u'en-us', u'hh': u'1.usa.gov', u'r': u'http://t.co/zcHxjnGZ', u'u': u'http://www.spc.noaa.gov/products/outlook/archive/2012/day1otlk_20121225_0100.html', u't': 1356397870, u'hc': 1356397201, u'll': [38.665798, -87.175903]}

a:  Mozilla/5.0 (iPod; CPU iPhone OS 511 like Mac OS X) AppleWebKit/534.46 (KHTML, like Gecko) Mobile/9B206
```



#### ç”¨çº¯ python è®¡ç®—æ—¶åŒº

æ•°æ®ä¸­æœ‰ä¸€ä¸ªå­—æ®µæ˜¯ `tz` ä»£è¡¨ timezoneã€‚å‡è®¾ç°åœ¨å¦‚æœè¦è®¡ç®—å“ªä¸ªæ—¶åŒºå‡ºç°æ¬¡æ•°æœ€å¤šã€‚

* **ç”¨çº¯ python æ¥è§£å†³è®¡ç®—æ—¶åŒºä¸ªæ•°**

`counts` å­˜çš„æ˜¯ `tz, count` é”®å€¼å¯¹

```python
# æœ€è ¢çš„æ–¹æ³•
def get_counts(sequence):
    counts = {}
    for x in sequence:
        if x in counts:
            counts[x] += 1
        else:
            counts[x] = 1
    return counts

# ç¨å¾®é«˜çº§ä¸€ç‚¹ç‚¹
def get_counts2(sequence):
    counts = collections.defaultdict(int)
    for x in sequence:
        counts[x] += 1
    return counts

# counting time zones in pure python
time_zones = [rec['tz'] for rec in records if 'tz' in rec] # å­˜äº† timezone çš„ list
print len(time_zones)                   # ä¸€å…±æœ‰å¤šå°‘æ¡è®°å½•åŒ…å«æ—¶åŒº
print get_counts(time_zones).__len__()  # è¿™äº›è®°å½•é‡Œæœ‰å¤šå°‘ç§ä¸åŒçš„æ—¶åŒº
counts = get_counts(time_zones)
print counts['America/New_York']		# æœ‰å¤šå°‘æ¡è®°å½•çš„æ—¶åŒºæ˜¯ America/New_York
```

ç»“æœä¼šæ˜¯

```python
2209
79
980
```

è¿™é‡Œçš„ `defaultdict`ï¼Œè§£é‡Šå¦‚ä¸‹å›¾ã€‚å› ä¸ºå¦‚æœæ²¡è¿™ä¸ªå…ƒç´ å°±è‡ªåŠ¨å« `int()` æ¥ç½®0ï¼Œæ‰€ä»¥ä¸ç”¨åƒç¬¬ä¸€ç§æ–¹æ³•é‚£æ ·å…ˆåˆ¤æ–­ key æ˜¯å¦å·²ç»å­˜åœ¨ã€‚ ![c2-defaultdict](../../images/postImages/python4data/c2-defaultdict.png)



* **ç”¨çº¯ python è®¡ç®—å‡ºç°æ¬¡æ•°æœ€å¤šçš„ 10 ä¸ªæ—¶åŒº**

`value_key_pairs` æ˜¯ä¸€ä¸ª listï¼Œé‡Œé¢è£…çš„æ˜¯ tupleï¼Œé»˜è®¤ç”¨ç¬¬ä¸€ä¸ªå…ƒç´ æ’åºã€‚

```python
def top_counts(count_dict, n=10):
    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]
    value_key_pairs.sort(reverse=True)
    return value_key_pairs

print top_counts(counts)
```

ç»“æœä¼šæ˜¯

```python
[(980, u'America/New_York'), (247, u''), (239, u'America/Chicago'), (205, u'America/Los_Angeles'), (73, u'Asia/Tokyo'), (57, u'Asia/Hong_Kong'), (47, u'Asia/Taipei'), (45, u'Europe/London'), (38, u'America/Denver'), (25, u'America/Indianapolis')]
```



å¦ä¸€ä¸ªæ›´é«˜çº§çš„æ–¹æ³•ä½¿ç”¨ python çš„ `Collection.Counter`

```python
counts = collections.Counter(time_zones)
print counts.most_common(10)
```

ä¼šå¾—åˆ°å’Œä¸Šä¸ªæ–¹æ³•ä¸€æ ·çš„ç»“æœ 

```python
[(u'America/New_York', 980), (u'', 247), (u'America/Chicago', 239), (u'America/Los_Angeles', 205), (u'Asia/Tokyo', 73), (u'Asia/Hong_Kong', 57), (u'Asia/Taipei', 47), (u'Europe/London', 45), (u'America/Denver', 38), (u'America/Indianapolis', 25)]
```



#### ç”¨ Pandas è®¡ç®—æ—¶åŒº   ğŸš©

Pandas çš„æ ¸å¿ƒæ•°æ®ç»“æ„æ˜¯ `DataFrame`, å¯ä»¥è®¤ä¸ºæ˜¯data çš„ table æˆ–è€…æ˜¯ spreadsheetã€‚

ç°åœ¨å…ˆä»¥åˆšåœ¨çš„ records list ä¸ºåŸºç¡€ï¼Œåˆ›å»º DataFrame

```python
# Counting Time Zones with pandas
frame = pd.DataFrame(records)
print frame
print frame['tz'][:10]
```

ç»“æœæ˜¯

```python
       gr        h            hc           hh        kw                l  \
0      IN   Vg7hKn  1.356397e+09    1.usa.gov       NaN           iembot   
1      MO   SsNjaC  1.352997e+09    1.usa.gov       NaN      o_d63rn9enb   
2      11   YFfXN8  1.356361e+09    1.usa.gov       NaN            bitly   
3      CA   UX2GJy  1.356137e+09  go.nasa.gov       NaN      nasatwitter   
4      Q9   VraFh0  1.356368e+09    1.usa.gov       NaN    cassinisaturn   
5      48   SMrlFn  1.355848e+09    1.usa.gov       NaN      obriennolan   
6      11   YFfXN8  1.356361e+09    1.usa.gov       NaN            bitly   
7      AZ   qePIGP  1.311670e+09    1.usa.gov       NaN            bitly   
8     NaN   RYPlzL  1.351190e+09  go.nasa.gov       NaN      nasatwitter   
9      08   U799Sf  1.356394e+09    1.usa.gov       NaN      o_9ptkdgt9d   
10    NaN      NaN           NaN          NaN       NaN              NaN   
11     NJ   V6Vw5O  1.356374e+09    1.usa.gov       NaN      twitterfeed   
12     CA   9ndvRw  1.273579e+09       bit.ly       NaN           gohsep   
13    NaN   Th1IdU  1.356381e+09    1.usa.gov       NaN            bitly   
14     CA   UX2GJy  1.356137e+09  go.nasa.gov       NaN      nasatwitter   
15     40   UX2GJy  1.356137e+09  go.nasa.gov       NaN      nasatwitter   
16     IN   Vg7hKn  1.356397e+09    1.usa.gov       NaN           iembot   
17     NY   TS5LMA  1.356372e+09    drudge.tw       NaN        drdg34568   
18    NaN   UX2GJy  1.356137e+09  go.nasa.gov       NaN      nasatwitter   
19    NaN   UX2GJy  1.356137e+09  go.nasa.gov       NaN      nasatwitter   

# frame['tz'][:10]
0    America/Indianapolis
1         America/Chicago
2        Europe/Amsterdam
3     America/Los_Angeles
4           Europe/London
5           Europe/Moscow
6              Asia/Seoul
7         America/Phoenix
8                        
9          Australia/West
Name: tz, dtype: object
```

ã€frame çš„ç±»å‹æ˜¯ DataFrameã€‚frame['tz'] å’Œ tz_counts éƒ½æ˜¯ Series ç±»å‹ã€‘

frame['tz']` æœ‰ä¸€ä¸ª` value_counts` å¯ä»¥å®ç°å¯¹äºæ—¶åŒºçš„ç»Ÿè®¡ã€‚

```python
tz_counts = frame['tz'].value_counts()
print tz_counts[:10]
```

ç»“æœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ° `value_counts` ç›´æ¥å®Œæˆäº†å¯¹äºæ—¶åŒºçš„<u>ç»Ÿè®¡ä»¥åŠæ’åº</u>ã€‚

```python
America/New_York                  980
                                  247
America/Chicago                   239
America/Los_Angeles               205
Asia/Tokyo                         73
Asia/Hong_Kong                     57
Asia/Taipei                        47
Europe/London                      45
America/Denver                     38
America/Indianapolis               25
```

ä¸è¿‡æœ‰çœ‹åˆ°ä¸Šé¢ 247 é‚£ä¸€é¡¹å¯¹åº”çš„æ—¶åŒºæ˜¯ç©ºçš„ã€‚æ˜¯å› ä¸ºåŸæ•°æ®æœ‰ 247 æ¡å°±æ²¡è¿™ä¸€é¡¹ã€‚ç°åœ¨å¸Œæœ›æŠŠ NA çš„æ ‡è¯†ä¸º Missingï¼Œç©ºå­—ç¬¦ä¸²çš„æ ‡ä¸º Unknown

```python
clean_tz = frame['tz'].fillna('Missing')
clean_tz[clean_tz == ''] = 'Unknown'
tz_counts = clean_tz.value_counts()
print clean_tz[:10]
```

ç»“æœä¸º

```python
America/New_York       980
Unknown                247
America/Chicago        239
America/Los_Angeles    205
Missing                120
Asia/Tokyo              73
Asia/Hong_Kong          57
Asia/Taipei             47
Europe/London           45
America/Denver          38
```

è“åæ¥ç”»å›¾äº†ğŸ’

```python
tz_counts[:10].plot(kind='barh', rot=0)
plt.show()
```

 ![c2_figure_1](../../images/postImages/python4data/c2_figure_1.png)

ä¸‹ä¸€ä¸ªé—®é¢˜ï¼š å¦‚ä½•åˆ‡å‰² Stringï¼Œæ¯”å¦‚è¯´åªè¦ç¬¬ä¸€ä¸ª token

```python
# ä¸åˆ‡å‰²
raw = pd.Series([x for x in frame.a.dropna()])
# åªè¦ç¬¬ä¸€ä¸ª token
results = pd.Series([x.split()[0] for x in frame.a.dropna()])
print raw[:5], results[:5]
```

å¯¹æ¯”ä¸‹ç»“æœ

```python
0    Mozilla/5.0 (iPod; CPU iPhone OS 5_1_1 like Ma...
1    Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...
2    Mozilla/5.0 (iPhone; CPU iPhone OS 6_0_1 like ...
3               GoogleProducer; (+http://goo.gl/7y4SX)
4    Mozilla/5.0 (iPhone; CPU iPhone OS 6_0_2 like ...
dtype: object 0        Mozilla/5.0
1        Mozilla/5.0
2        Mozilla/5.0
3    GoogleProducer;
4        Mozilla/5.0
dtype: object
```

 åˆ©ç”¨ Pandas å’Œ NumPy è¿˜èƒ½è½»æ˜“å®Œæˆæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œæ¯”å¦‚è¯´æŠŠæŸä¸ªæ—¶åŒºå†è¿›è€Œåˆ†ä¸ºç”¨ Windows å’Œ ä¸ç”¨ Windows çš„ã€‚

```python
# OS æ˜¯ä¸æ˜¯ windows
cframe = frame[frame.a.notnull()] # å…ˆå‰”é™¤ a ä¸ºç©ºçš„
operating_system = np.where(cframe['a'].str.contains('Windows'),'Windows','Not Windows')
print operating_system[:5]
```

çœ‹ä¸‹ç»“æœ

```python
['Not Windows' 'Windows' 'Not Windows' 'Not Windows' 'Not Windows']
```

è¿™æ ·ç³»ç»Ÿå’Œæ—¶åŒºè¿˜æ²¡åˆ°ä¸€èµ·ï¼Œç°åœ¨å°†ä»–ä»¬ç»„åˆèµ·æ¥

â“è¿™é‡Œçš„ `groupby`, `unstack`ä»€ä¹ˆçš„è¿˜æ²¡å¼„æ‡‚

```python
# group the data by timezone and operating system
# group the data by its time zone column and this new list of operating systems
by_tz_os = cframe.groupby(['tz',operating_system])
# The group counts, analogous to the value_counts function above, can be computed
# using size. This result is then reshaped into a table with unstack
agg_counts = by_tz_os.size().unstack().fillna(0)
print agg_counts[:10]
```

ç»“æœä¼šæ˜¯

```python
                                Not Windows  Windows
tz                                                  
                                      191.0     56.0
Africa/Cairo                            0.0      1.0
Africa/Ceuta                            1.0      0.0
Africa/Johannesburg                     2.0      0.0
Africa/Lagos                            0.0      5.0
America/Anchorage                       2.0      1.0
America/Anguilla                        1.0      0.0
America/Argentina/Buenos_Aires          0.0      4.0
America/Aruba                           1.0      0.0
America/Asuncion                        0.0      1.0
```

æœ€åè¿˜éœ€è¦é’ˆå¯¹æ—¶åŒºè¿›è¡Œæ’åº

```python
# select top overall time zones
indexer = agg_counts.sum(1).argsort()
print indexer[:10]
count_subset = agg_counts.take(indexer)[-10:]
print count_subset
```

ç»“æœæ˜¯

```python
tz
                                  39
Africa/Cairo                      29
Africa/Ceuta                      30
Africa/Johannesburg               32
Africa/Lagos                      37
America/Anchorage                 44
America/Anguilla                  45
America/Argentina/Buenos_Aires    51
America/Aruba                     24
America/Asuncion                  58
dtype: int64
                      Not Windows  Windows
tz                                        
America/Indianapolis         17.0      8.0
America/Denver               19.0     19.0
Europe/London                31.0     14.0
Asia/Taipei                   0.0     47.0
Asia/Hong_Kong               46.0     11.0
Asia/Tokyo                   56.0     17.0
America/Los_Angeles         131.0     74.0
America/Chicago             135.0    104.0
                            191.0     56.0
America/New_York            734.0    246.0
```

æœ€åç”»å›¾ğŸ’

ä¸€å¼ æ˜¯æ™®é€šçš„ï¼Œä¸€å¼ æ˜¯ normalize ä¹‹å

```python
count_subset.plot(kind="barh", stacked=True)
normed_subset = count_subset.div(count_subset.sum(1), axis=0)
normed_subset.plot(kind="barh", stacked=True)
```

 ![c2_figure_2](../../images/postImages/python4data/c2_figure_2.png)

 ![c2_figure_3](../../images/postImages/python4data/c2_figure_3.png)